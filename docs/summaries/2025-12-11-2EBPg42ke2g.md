# Trace OpenRouter Calls to LangSmith — No Code Changes Needed

**Channel:** LangChain
**Published:** 2025-12-11
**Video:** [Watch on YouTube](https://youtube.com/watch?v=2EBPg42ke2g)

---

# 如何結合使用 OpenRouter 的廣播功能與 LangChain 及 LangSmith

## 重點摘要
OpenRouter 的「廣播」功能可將 LangSmith 的設定儲存在雲端，讓開發者在程式碼中只需管理 OpenRouter API 金鑰。這不僅簡化了將 LLM 追蹤資料傳送到 LangSmith 的過程，還能讓使用者輕鬆切換不同的語言模型供應商，同時維持完整的可觀察性。

## 故事大綱
- **開場**：LangChain 的 Tanish 介紹 OpenRouter 的新「廣播」(broadcast) 功能，並說明其核心優勢：它能將 LangSmith 等觀測工具的設定資訊（如 API 金鑰）儲存在伺服器端。
- **中段**：他逐步示範設定流程。首先，在 OpenRouter 網站介面建立一把新的 API 金鑰，然後進入「廣播」功能，設定一個指向 LangSmith 的目的地，並貼上 LangSmith 的 API 金鑰。接著，他展示一段 Python 程式碼，其中 LangChain 的 `init_chat_model` 僅需設定 OpenRouter 的 URL 及 API 金鑰即可。他先從 OpenRouter 介面直接發送一筆測試追蹤，並在 LangSmith 中成功看到紀錄，驗證了設定。
- **結尾**：Tanish 執行 Python 程式碼，先是呼叫了 Bedrock 模型，然後僅修改一行程式碼，就換成了 OpenAI 模型。兩次呼叫的追蹤紀錄都成功地出現在 LangSmith 中，完美展示了此架構的彈性與便利性。

## 關鍵見解
1.  **伺服器端設定**：廣播功能將目的地（如 LangSmith）的 API 金鑰等敏感資訊儲存在 OpenRouter 平台，不需在應用程式碼中曝露，更安全也更方便管理。
2.  **簡化程式碼**：開發者的應用程式中只需要 OpenRouter 的 API 金鑰，讓程式碼更乾淨，並專注於核心邏輯。
3.  **模型無關性**：可以輕鬆地在 OpenRouter 支援的不同 LLM 供應商（如 Bedrock、OpenAI）之間切換，所有追蹤紀錄都會統一發送到 LangSmith，無需更改監控設定。
4.  **與 OpenAI 相容**：透過 LangChain 使用 OpenRouter 時，可將其視為與 OpenAI 相容的 API 端點，簡化了整合的複雜度。
5.  **集中管理**：OpenRouter 提供一個中央儀表板，方便跨各種模型追蹤 LLM 的成本與用量，與 LangSmith 的可觀察性形成互補。

## 精彩時刻
-   核心價值：「廣播最酷的地方是它把目的地資訊存在伺服器端。所以你在程式碼中唯一要擔心的就只有你的 OpenRouter API 金鑰。」
-   Tanish 僅用一行程式碼就從 Bedrock 模型換成 OpenAI 模型，並在 LangSmith 上看到兩筆追蹤紀錄，流暢地展現了高度的彈性。
-   無需編寫程式碼，直接從 OpenRouter UI 就能發送測試追蹤到 LangSmith，提供了一種快速驗證設定是否正確的方法。

---

# How to Use OpenRouter's Broadcast Feature with LangChain and LangSmith

## TL;DR
OpenRouter's "broadcast" feature simplifies sending LLM traces to LangSmith by storing the LangSmith configuration server-side. This allows developers to only manage their OpenRouter API key in their code, making it effortless to switch between different LLM providers while maintaining full observability.

## Story Flow
- **Beginning**: Tanish from LangChain introduces OpenRouter's new broadcast feature, explaining its core benefit: destination configurations (like LangSmith's API key) are stored on the server, not in the user's code.
- **Middle**: He demonstrates the setup process step-by-step. First, he creates a new API key in the OpenRouter UI. Then, he configures a broadcast to LangSmith by providing a LangSmith API key. He shows a Python script using LangChain's `init_chat_model` that only requires the OpenRouter base URL and API key. To verify the connection, he sends a test trace directly from the OpenRouter UI and confirms it appears in LangSmith.
- **End**: Tanish runs the script, first calling a Bedrock model and then seamlessly switching to an OpenAI model with a single line change. The traces for both calls successfully appear in LangSmith, highlighting the system's flexibility and ease of use.

## Key Insights
1.  **Server-Side Configuration**: The broadcast feature stores destination credentials (e.g., for LangSmith) on the OpenRouter platform, keeping them secure and out of your application code.
2.  **Simplified Code**: Your application only needs the OpenRouter API key, which makes the code cleaner and allows you to focus on the core logic.
3.  **Model Agnostic**: You can easily swap between different LLM providers supported by OpenRouter (like Bedrock, OpenAI) with a one-line code change, and all traces are consistently sent to LangSmith without any changes to the monitoring setup.
4.  **OpenAI Compatibility**: When using LangChain, OpenRouter is treated as an OpenAI-compatible API endpoint, which simplifies the integration process.
5.  **Centralized Management**: OpenRouter provides a central dashboard to track costs and usage across various models, complementing LangSmith's observability features.

## Notable Moments
-   The core value proposition: "The cool thing about broadcast is it stores destination information... server side. So the only thing that you need to worry about in your code is your open router API key."
-   The live demo where he switches from a Bedrock model to an OpenAI model with a simple change, with both traces fluidly appearing in LangSmith.
-   The ability to send a test trace directly from the OpenRouter UI to LangSmith provides instant, code-free verification of the setup.
