# Model Fallback Middleware (Python)

**Channel:** LangChain
**Published:** 2025-11-18
**Video:** [Watch on YouTube](https://youtube.com/watch?v=8rCRO0DUeIM)

---

# LangChain 模型備援中介軟體介紹

## 重點摘要
LangChain 推出了新的「模型備援」(Model Fallback) 中介軟體，能讓應用程式在主要模型（例如因服務中斷或 API 額度用盡）失效時，自動切換至備用模型。這項功能大幅提升了應用的可靠性與韌性，甚至支援跨供應商的備援。

## 故事大綱
- **開場**：LangChain 團隊的 Sydney 點出語言模型服務中斷的不可預測性，並以此為引，介紹了能解決此問題的新功能——模型備援中介軟體。
- **中段**：她快速導覽了新版文件，解釋此功能如何運作。她強調一個關鍵優勢：可以從一個供應商的模型（如 OpenAI）備援至另一個供應商的模型（如 Anthropic），增加系統彈性。她說明，只需在主要模型上附加 `.with_fallbacks()` 方法並提供備援模型列表，即可輕鬆完成設定。
- **結尾**：Sydney 透過一個簡單的腳本進行實作展示。她故意設定前兩個模型名稱錯誤以模擬失敗，最終應用程式成功備援至第三個可用的模型 (GPT-4o mini)，並得到正確答案「15 * 23 = 345」。整個備援過程可透過 LangSmith 的追蹤視圖清楚看見。

## 關鍵見解
- **提升應用韌性**：有效應對模型服務中斷、API 額度耗盡等突發狀況，確保應用程式持續運作不中斷。
- **支援跨供應商備援**：最大的亮點之一，可設定不同模型供應商之間的備援（例如 OpenAI -> Anthropic），避免被單一平台綁定，並提升整體可靠性。
- **實作簡單直觀**：只需在建立代理 (agent) 時，於主要模型後方鏈式呼叫 `.with_fallbacks()` 並傳入備援模型列表即可，語法清晰易懂。
- **過程透明可追蹤**：搭配 LangSmith 工具，可以清楚看到每一次模型呼叫的失敗、備援切換，直到最後成功為止的完整流程，便於除錯與監控。

## 精彩時刻
- **核心價值主張**：「模型服務中斷可能極度不可預測，但幸運的是，有了 LangChain 的模型備援中介軟體，您應用程式的可靠性就不必如此了。」
- **生動的失敗模擬**：透過故意寫錯模型名稱來展示備援流程，讓觀眾清楚看到從連續失敗到成功切換的實際過程，非常有說服力。
- **輕鬆的片刻**：Sydney 在提到可以加入「任意數量 (any number) 的備援」時，發出了一個輕快的鼻息聲，為這場技術介紹增添了一絲輕鬆的人情味。

---

# Introducing LangChain's Model Fallback Middleware

## TL;DR
LangChain's new Model Fallback middleware makes applications more reliable by automatically switching to backup models when a primary model fails due to an outage, exhausted API credits, or other issues. This feature even supports falling back across different model providers.

## Story Flow
- **Beginning**: Sydney from the LangChain team introduces the problem of unpredictable model outages and presents the new model fallback middleware as the solution for building more resilient applications.
- **Middle**: She walks through the new documentation, explaining how the middleware works. A key benefit highlighted is the ability to fall back from a model from one provider (e.g., OpenAI) to another (e.g., Anthropic). She shows that implementation is as simple as adding the `.with_fallbacks()` method to the primary model when creating an agent.
- **End**: Sydney gives a practical demo using a script. She intentionally configures the first two models to fail (using typos in their names), and the application successfully falls back to the third, working model (GPT-4o mini) to get the correct answer to "15 * 23," which is 345. The entire process is visualized using the LangSmith trace view.

## Key Insights
- **Enhanced Application Resilience**: It provides a safety net against unexpected model failures like outages or exhausted API credits, ensuring your application remains functional.
- **Cross-Provider Fallbacks**: A major advantage is the ability to set up fallbacks between different providers (e.g., OpenAI -> Anthropic), preventing vendor lock-in and increasing reliability.
- **Simple and Intuitive Implementation**: You can set it up by simply chaining the `.with_fallbacks()` method to your primary model and passing in a list of backup models. The syntax is clean and easy to understand.
- **Transparent and Traceable**: When used with tools like LangSmith, the entire fallback chain is visible, showing each failed attempt and the final successful call, which is great for debugging and monitoring.

## Notable Moments
- **The Core Value Proposition**: "Model outages can be incredibly unpredictable, but luckily with Langchain's new model fallback middleware, the reliability of your application doesn't have to be."
- **The Vivid Failure Simulation**: Intentionally using incorrect model names to demonstrate the fallback mechanism in action is highly effective, as it clearly shows the progression from failure to success.
- **A Lighthearted Moment**: Sydney gives a small snort while mentioning you can add "any number of fallbacks," adding a human and relatable touch to the technical presentation.
