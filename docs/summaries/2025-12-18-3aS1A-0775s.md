# Approaches for Managing Agent Memory

**Channel:** LangChain
**Published:** 2025-12-18
**Video:** [Watch on YouTube](https://youtube.com/watch?v=3aS1A-0775s)

---

# 深度代理的記憶模式：顯性與隱性更新

## 重點摘要
本影片介紹了 AI 代理（特別是深度代理）的兩種核心記憶模式。「顯性記憶」是透過直接命令讓代理記住事情，「隱性記憶」則是代理透過反思過去的互動紀錄，自動學習並提煉出用戶的偏好與工作流程。影片最終展示了代理如何分析 Langsmith 中的對話紀錄，成功將一個隱含的工作偏好更新到其全域記憶中。

## 故事大綱
- **開場：** 講者 Lance 提出 AI 代理的記憶可以分為「顯性更新」和「隱性更新」兩種模式。
- **中段：**
    - 首先解釋**顯性記憶**，以 Claude 和 Deep Agent CLI 為例。使用者可以直接用自然語言命令代理「記住我喜歡狗」，代理會自動將這條偏好寫入 `agent.md` 這個全域設定檔中。
    - 接著介紹更精妙的**隱性記憶**，即代理從互動中「領悟」出的偏好。Lance 引用了學術論文並展示他為 Claude 寫的 `reflect`（反思）指令。
    - 影片的核心是展示 Deep Agent 如何實現隱性記憶。代理的互動過程會被記錄到 Langsmith 中成為「執行緒 (threads)」。Lance 取回一個包含他除錯工作流程偏好的執行緒，並命令代理對其進行反思。
- **結尾：** 代理成功地從複雜的對話紀錄中，提煉出「當運行 langgraph 腳本後，自動使用 `langfetch` 技能來檢查追蹤日誌」這一條通用偏好，並將其寫入全域的 `agent.md` 記憶檔案。這個成功的演示證明了隱性記憶的強大潛力。

## 關鍵見解
1.  **記憶的二元性**：代理的記憶分為兩種，一種是直接聽令行事（顯性），另一種是從經驗中學習（隱性），後者讓代理更具智慧。
2.  **顯性記憶是基礎**：透過直接編輯 `agent.md` 檔案，使用者可以為代理設定一個永不忘記的基本背景和指令，就像給它一份核心說明書。
3.  **隱性記憶是進階**：代理透過「反思」過去的對話，能自動學習並泛化用戶的習慣與偏好，讓自己越來越懂你，而無需你事事都明確指示。
4.  **日誌是記憶的土壤**：像 Langsmith 這樣的工具至關重要，它儲存了代理所有互動的詳細紀錄（traces/threads），為隱性記憶的「反思」過程提供了必要的原始資料。
5.  **反思不只是附加**：這個過程並非簡單地增加筆記，而是會提煉、重組甚至改寫現有記憶，以形成更通用、更精準的規則，避免資訊冗餘和混淆。

## 精彩時刻
- **「記住我喜歡狗」**：一個簡單的指令，代理立即正確地修改了其全域設定檔，直觀展示了「顯性記憶」的運作方式。
- **「啊，這太酷了！」**：當代理讀取完一份複雜的 Langsmith 對話紀錄後，精準地總結出講者隱含的工作流程偏好時，這是整個流程的「啊哈時刻」。
- **最終驗證**：打開 `agent.md` 檔案，看到那條由代理自動提煉並寫入的複雜新規則，完美證明了「隱性記憶」更新機制的成功。

---

# Memory Patterns for Deep Agents: Explicit and Implicit Updating

## TL;DR
This video explains two core memory patterns for AI agents, specifically "deep agents." "Explicit memory" involves directly telling the agent what to remember, while "implicit memory" allows the agent to automatically learn and distill a user's preferences and workflows by reflecting on past interaction logs. The video culminates in a demo where an agent analyzes its conversation history from Langsmith to successfully add an implicit workflow preference to its global memory.

## Story Flow
- **Beginning:** The speaker, Lance, introduces the idea that agent memory can be divided into two models: "explicit updating" and "implicit updating."
- **Middle:**
    - He first explains **explicit memory** using the Claude and Deep Agent CLIs as examples. A user can directly tell the agent, "remember that I like dogs," and the agent will write this preference into its global `agent.md` configuration file.
    - He then introduces the more nuanced **implicit memory**, where the agent learns preferences from interactions. Lance references academic papers and a `reflect` command he built for Claude.
    - The core of the video demonstrates implicit memory with Deep Agents. An agent's interactions are logged as "threads" in Langsmith. Lance retrieves a thread containing his debugging workflow preference and instructs the agent to reflect on it.
- **End:** The agent successfully distills a general rule from the complex log: "after running a langgraph script, use the `langfetch` skill to inspect the trace." It then writes this new rule into its global `agent.md` memory file, proving the power of the implicit memory mechanism.

## Key Insights
1.  **The Duality of Memory:** Agents have two memory types: one that follows direct orders (explicit) and one that learns from experience (implicit), with the latter making the agent truly intelligent.
2.  **Explicit Memory as a Foundation:** By directly editing an `agent.md` file, users can give an agent a permanent set of background context and instructions, like a core manual it never forgets.
3.  **Implicit Memory is the Advanced Skill:** By "reflecting" on past conversations, the agent can automatically learn and generalize a user's habits, becoming more helpful over time without needing explicit instructions for everything.
4.  **Logs are the Soil for Memory:** Tools like Langsmith are crucial because they store the detailed interaction histories (traces/threads) that provide the raw material for the implicit memory "reflection" process.
5.  **Reflection is More Than Appending:** This process doesn't just add notes. It distills, refines, and can even rewrite existing memories to form more accurate, general-purpose rules, preventing redundancy and context confusion.

## Notable Moments
- **"Remember that I like dogs":** A simple command that leads to the agent correctly modifying its global config file, providing a clear demo of how explicit memory works.
- **"Ah, see this is cool!":** The "aha!" moment when the agent, after processing a complex Langsmith log, perfectly summarizes the speaker's implied workflow preference into a clean, reusable rule.
- **The Final Verification:** Opening the `agent.md` file to see the newly added, complex rule, which was automatically distilled and written by the agent, serving as perfect confirmation that the implicit memory update succeeded.
