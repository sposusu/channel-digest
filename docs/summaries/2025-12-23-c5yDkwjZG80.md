# Learning Skills with Deepagents

**Channel:** LangChain
**Published:** 2025-12-23
**Video:** [Watch on YouTube](https://youtube.com/watch?v=c5yDkwjZG80)

---

# 用深度代理進行持續學習與技能創造

## 重點摘要
AI 代理可以透過反思其過去的行動來學習新的、可重複使用的技能。這部影片展示了一個「深度代理 (Deep Agent)」如何分析先前一次互動的紀錄 (trace)，並自動地創造一個永久性的新「技能」，從而實現一個強大的持續學習循環。

## 故事大綱
- **開場**：講者 Lance 介紹了 AI 代理與人類在「持續學習」能力上的差距，並提出可透過大型語言模型的「上下文學習 (in-context learning)」來彌補。他概述了一個持續學習的循環：代理行動 -> 捕捉軌跡 -> 反思軌跡。
- **中段**：影片聚焦於「反思」能實現的三件事中的第三項：學習新技能。Lance 進行了一場實作演示：首先，他載入一個既有的「技能創造者」技能；接著，他用 `langsmith fetch` 工具取回一份先前的代理互動紀錄；最後，他啟動深度代理並指示它「閱讀這份紀錄，並依此創造一個新技能」。代理遵循指令，利用「技能創造者」的知識，一步步為 `langsmith fetch` 這個工具建立了新的技能資料夾和說明檔 (`skill.md`)。
- **結尾**：代理成功創造並驗證了新技能。Lance 重新啟動代理，證明這個名為 `langsmith_fetch_skill` 的新技能已被永久保存並可供未來使用，完整展示了代理如何透過反思來實現自我提升。

## 關鍵見解
1.  **持續學習循環**：AI 代理可以透過「行動 -> 記錄軌跡 -> 反思軌跡」的循環來學習與進化，而不是讓知識停留在固定狀態。
2.  **反思的三種路徑**：反思過去的軌跡可以有三種用途：更新記憶（學習事實）、優化核心指令（改進提示），或是像影片中展示的，學習全新的技能。
3.  **技能即標準作業程序 (SOP)**：在深度代理的框架中，「技能」是一種被封裝的標準作業程序，存放在包含 `skill.md` 文件的資料夾中，讓代理能夠可靠地重複使用特定能力。
4.  **元學習的體現**：代理使用一個「技能創造者」技能來學習如何根據過去的經驗創造一個全新的技能，這是一種「學習如何學習」的元學習（meta-learning）的實際應用。
5.  **從經驗到知識的轉化**：演示的核心是將一次性的互動經驗（對話紀錄）轉化為一個永久、可重複使用的知識資產（一個新技能），這是讓代理能力隨時間增長的關鍵。

## 精彩時刻
- **關鍵指令**：「讀取最新線程目錄中的 JSON... 仔細反思，並利用這些見解創造一個新的深度代理技能。」這個簡單的指令啟動了整個自主學習過程。
- **代理的自主工作流**：影片中代理自主地執行 `mkdir` 創建資料夾、`echo` 寫入 `skill.md` 文件，並運行驗證腳本，整個過程就像一個無需干預的自主開發者。
- **學習成果的驗證**：「它被創造了、被儲存了，現在我可以重複使用這個特定的工具... 這是技能學習的一個絕佳範例。」這句話總結了整個演示的成功與其重要意義。

---

# Continual Learning & Skill Creation with Deep Agents

## TL;DR
AI agents can learn new, reusable skills by reflecting on their past actions. This video demonstrates how a "Deep Agent" analyzes a trace of a previous session to automatically create a new, persistent "skill," enabling a powerful continual learning loop.

## Story Flow
- **Beginning**: Speaker Lance introduces the gap between human and AI agent learning capabilities, proposing "in-context learning" as a solution. He outlines a continual learning loop: Agent acts -> Trajectories are traced -> Agent reflects on traces.
- **Middle**: The video focuses on the third of three reflection types: learning new skills. Lance performs a live demo: he loads a pre-existing "skill creator" skill, uses the `langsmith fetch` utility to retrieve the log (trace) of a prior agent session, and then instructs the Deep Agent to "read the trace and create a new skill" based on it. The agent follows the command, using the "skill creator's" knowledge to build a new skill folder and `skill.md` file for the `langsmith fetch` utility.
- **End**: The agent successfully creates and validates the new skill. Lance restarts the agent, showing that the new `langsmith_fetch_skill` is now permanently saved and available for future use. This demonstrates a complete cycle of an agent improving itself through reflection.

## Key Insights
1.  **The Continual Learning Loop**: AI agents can learn and evolve through a cycle of Acting -> Tracing Trajectories -> Reflecting on Trajectories, rather than having their knowledge remain static.
2.  **Three Paths of Reflection**: Reflecting on past trajectories can be used to update memories (learn facts), optimize core instructions (improve prompts), or, as shown in the video, learn entirely new skills.
3.  **Skills as Standard Operating Procedures (SOPs)**: In the Deep Agents framework, a "skill" is a packaged SOP, contained in a folder with a `skill.md` file, which allows the agent to reuse a capability reliably.
4.  **Meta-Learning in Action**: The agent uses a "skill creator" skill to learn how to create a *new* skill from experience, demonstrating a practical application of meta-learning ("learning how to learn").
5.  **From Experience to Knowledge**: The core of the demo is the conversion of a one-off interaction (the session trace) into a permanent, reusable knowledge asset (a new skill), which is key to growing an agent's capabilities over time.

## Notable Moments
- **The Key Prompt**: "Read the JSON in the most recent thread directory... reflect on it carefully and use the insights to create a new deep agent skill." This simple instruction kicks off the entire autonomous learning process.
- **The Agent's Autonomous Workflow**: The agent is shown independently running `mkdir` to create the skill directory, `echo` to write the `skill.md` file, and then running a validation script, acting much like a hands-off, autonomous developer.
- **The Payoff Quote**: "It's created, it's saved and now I can repeatedly use this particular utility... This is a great example of skill learning." This line summarizes the success and significance of the entire demonstration.
