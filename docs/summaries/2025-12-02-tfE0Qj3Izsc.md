# Summarization Middleware (Python)

**Channel:** LangChain
**Published:** 2025-12-02
**Video:** [Watch on YouTube](https://youtube.com/watch?v=tfE0Qj3Izsc)

---

# Langchain 的摘要中介軟體：優化 AI 代理人的情境工程

## 重點摘要
Langchain 推出了一款新的摘要中介軟體，旨在解決 AI 代理人（agent）在長時間運行中遇到的對話歷史過長問題。透過自動壓縮對話內容，此工具能幫助代理人專注於最關鍵的資訊，從而優化其在執行後續任務時的表現。

## 故事大綱
- **開場**：影片由 Langchain 的 Sydney 開始，介紹了「情境工程」（Context Engineering）的核心概念——在對的時機給予模型對的資訊和工具。她指出，隨著代理人運行時間變長，過長的對話歷史成為一大挑戰，而「摘要」正是解決此問題的關鍵。
- **中段**：Sydney 展示了 Langchain 新的摘要中介軟體文件，其介面相當簡單。使用者只需設定摘要用的模型、觸發摘要的時機（例如當上下文佔用超過 70%），以及摘要後保留的內容比例（例如保留 30%）。她接著透過一個實際程式碼範例，建立了一個能從維基百科抓取資料的代理人，並詳細說明了如何配置此中介軟體。其中一個亮點是 Langchain 的「模型設定檔」（model profiles）套件，它能自動獲取模型的上下文視窗大小等資訊，讓設定更直觀。
- **結尾**：為了觸發摘要功能，Sydney 在一個即時偵錯環境中，連續要求代理人查詢多位美國開國元勳的生日，故意用大量資訊填滿上下文視窗。當查詢到第三位時，摘要中介軟體被成功觸發，自動生成了前面內容的摘要，然後再執行最後的查詢任務。影片最後透過追蹤視圖（trace view）清晰地展示了整個摘要過程。

## 關鍵見解
1.  **情境工程是關鍵**：優化代理人行為的核心在於有效管理其「情境」，確保它在做決策時能獲取最相關的資訊。
2.  **摘要解決長對話問題**：對於需要長時間運行的代理人，摘要功能可以自動濃縮對話歷史，避免重要資訊被淹沒在大量文字中。
3.  **設定簡單直觀**：Langchain 的中介軟體只需幾行程式碼即可配置，能指定觸發條件和保留策略，大幅簡化了開發流程。
4.  **智慧化的模型適配**：透過「模型設定檔」套件，Langchain 能自動了解不同模型的特性（如上下文視窗大小），讓開發者不必手動查詢和設定這些參數。
5.  **過程透明可追蹤**：開發者可以透過 Langchain 的偵錯工具清楚看到摘要何時被觸發，以及摘要後的內容如何被傳遞給下一步，便於除錯和優化。

## 精彩時刻
- **真實世界的比喻**：Sydney 提到，就像 `Claude Code` 在對話太長時會自動壓縮內容一樣，開發者現在也可以用 Langchain 輕鬆實現相同功能。
- **具體的程式碼範例**：影片中建立了一個查詢維基百科的代理人，這個例子非常有效地展示了中介軟體如何在實際應用中處理大量資訊。
- **核心理念金句**：「情境工程就是在對的時機，給予你的模型對的資訊和工具，以便它能執行給定的任務。」

---

# Langchain's Summarization Middleware: Optimizing Context Engineering for AI Agents

## TL;DR
Langchain has introduced a new summarization middleware designed to solve the problem of overly long conversation histories in long-running AI agents. By automatically compacting context, this tool helps the agent focus on the most critical information, thereby optimizing its performance on subsequent steps.

## Story Flow
- **Beginning**: The video starts with Sydney from Langchain introducing the concept of "Context Engineering"—giving a model the right information and tools at the right time. She highlights that as agents run for longer, their extensive conversation histories become a challenge, and summarization is the key solution.
- **Middle**: Sydney walks through the documentation for Langchain's new summarization middleware, which has a simple interface. Users can define a model for summarization, a trigger condition (e.g., when context exceeds 70% of the window), and a retention policy (e.g., keep 30%). She then dives into a code example, building an agent that retrieves data from Wikipedia and explaining how to configure the middleware. A key feature mentioned is Langchain's "model profiles" package, which automatically provides model-specific information like context window size, making configuration more intuitive.
- **End**: To demonstrate the middleware in action, Sydney uses a live debugger to ask the agent for the birthdays of several US founding fathers, intentionally filling the context window with verbose information. Upon the third query, the summarization middleware successfully triggers, generates a summary of the previous turns, and then executes the final query. The entire process is clearly shown in the trace view.

## Key Insights
1.  **Context Engineering is Crucial**: The core of optimizing agent behavior is effectively managing its context to ensure it has the most relevant information for decision-making.
2.  **Summarization Solves Long Histories**: For agents that run for extended periods, summarization automatically condenses the conversation history, preventing important information from getting lost in the noise.
3.  **Simple and Intuitive Configuration**: The Langchain middleware can be configured with just a few lines of code, allowing developers to specify trigger conditions and retention policies, greatly simplifying development.
4.  **Intelligent Model Adaptation**: With the "model profiles" package, Langchain automatically understands the capabilities of different models (like context window size), freeing developers from manual configuration.
5.  **Transparent and Debuggable Process**: Developers can use Langchain's tracing tools to see exactly when a summary is triggered and how the summarized content is passed to the next step, making it easy to debug and optimize.

## Notable Moments
- **Real-world Analogy**: Sydney mentions that just as `Claude Code` autocompacts your conversation history when it gets too long, developers can now achieve the same with Langchain.
- **Concrete Code Example**: The video's agent, built to query Wikipedia, serves as an effective demonstration of how the middleware handles large amounts of information in a practical application.
- **Defining Quote**: "Context engineering is giving your model... the right information and tools at the right time so that it can execute a given task."
